{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da8b174b",
   "metadata": {},
   "source": [
    "## Baseline Seq2Seq para suma de enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dc3312",
   "metadata": {},
   "source": [
    "Entrenamos un modelo Seq2Seq baseline (sin atención) sobre un data toy de suma de enteros. Esto nos servirá para luego poder comparar variantes de atención."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9564b68c",
   "metadata": {},
   "source": [
    "### Carga y generación del toy-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "557cb453",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "from src.utils import generate_toy_data, load_toy_data, save_toy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3103a6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toy data cargado (train=8000, val=2000)\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "DATA_PATH = os.path.join(PROJECT_ROOT, \"data\", \"toy_seq2seq.json\")\n",
    "\n",
    "if os.path.exists(DATA_PATH):\n",
    "    train_data, val_data = load_toy_data(DATA_PATH)\n",
    "    print(f\"Toy data cargado (train={len(train_data)}, val={len(val_data)})\")\n",
    "else:\n",
    "    train_data, val_data = generate_toy_data()\n",
    "    os.makedirs(os.path.dirname(DATA_PATH), exist_ok=True)\n",
    "    save_toy_data(train_data, val_data, DATA_PATH)\n",
    "    print(f\"Toy data generado y guardado (train={len(train_data)}, val={len(val_data)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d66ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: [('33+91', '124'), ('88+91', '179'), ('24+32', '56'), ('61+41', '102'), ('63+82', '145')]\n",
      "Val data: [('91+78', '169'), ('6+22', '28'), ('21+80', '101'), ('35+80', '115'), ('24+7', '31')]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train data: {train_data[:5]}\")\n",
    "print(f\"Val data: {val_data[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8849da1",
   "metadata": {},
   "source": [
    "### Entrenamiento y evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "185ba96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import src.seq2seq_baseline\n",
    "importlib.reload(src.seq2seq_baseline)\n",
    "from src.seq2seq_baseline import Seq2SeqBaseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d139e666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 14, pad: 0, sos: 1, eos: 2\n"
     ]
    }
   ],
   "source": [
    "from src.utils import CharTokenizer\n",
    "from src.seq2seq_baseline import Seq2SeqBaseline\n",
    "\n",
    "tokenizer = CharTokenizer()\n",
    "print(f\"Vocab size: {tokenizer.vocab_size}, pad: {tokenizer.pad_token_id}, sos: {tokenizer.sos_token_id}, eos: {tokenizer.eos_token_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "be5dc82d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo en dispositivo: cpu\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqBaseline(tokenizer, emb_size=32, hidden_size=64, lr=1e-3)\n",
    "print(f\"Modelo en dispositivo: {model.device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da631612",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30  Loss: 0.3101\n",
      "Epoch 2/30  Loss: 0.3061\n",
      "Epoch 3/30  Loss: 0.2991\n",
      "Epoch 4/30  Loss: 0.2889\n",
      "Epoch 5/30  Loss: 0.2818\n",
      "Epoch 6/30  Loss: 0.2874\n",
      "Epoch 7/30  Loss: 0.2694\n",
      "Epoch 8/30  Loss: 0.2625\n",
      "Epoch 9/30  Loss: 0.2721\n",
      "Epoch 10/30  Loss: 0.2581\n",
      "Epoch 11/30  Loss: 0.2566\n",
      "Epoch 12/30  Loss: 0.2615\n",
      "Epoch 13/30  Loss: 0.2531\n",
      "Epoch 14/30  Loss: 0.2544\n",
      "Epoch 15/30  Loss: 0.2303\n",
      "Epoch 16/30  Loss: 0.2502\n",
      "Epoch 17/30  Loss: 0.2350\n",
      "Epoch 18/30  Loss: 0.2366\n",
      "Epoch 19/30  Loss: 0.2184\n",
      "Epoch 20/30  Loss: 0.2197\n",
      "Epoch 21/30  Loss: 0.2100\n",
      "Epoch 22/30  Loss: 0.2255\n",
      "Epoch 23/30  Loss: 0.2319\n",
      "Epoch 24/30  Loss: 0.2113\n",
      "Epoch 25/30  Loss: 0.2215\n",
      "Epoch 26/30  Loss: 0.2057\n",
      "Epoch 27/30  Loss: 0.2082\n",
      "Epoch 28/30  Loss: 0.1997\n",
      "Epoch 29/30  Loss: 0.2060\n",
      "Epoch 30/30  Loss: 0.2025\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "model.train(train_data, epochs=30, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4355601b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.5115\n"
     ]
    }
   ],
   "source": [
    "# Evaluación\n",
    "model.evaluate(val_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
